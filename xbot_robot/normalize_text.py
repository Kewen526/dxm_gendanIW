# ä½¿ç”¨æé†’:
# 1. xbotåŒ…æä¾›è½¯ä»¶è‡ªåŠ¨åŒ–ã€æ•°æ®è¡¨æ ¼ã€Excelã€æ—¥å¿—ã€AIç­‰åŠŸèƒ½
# 2. packageåŒ…æä¾›è®¿é—®å½“å‰åº”ç”¨æ•°æ®çš„åŠŸèƒ½ï¼Œå¦‚è·å–å…ƒç´ ã€è®¿é—®å…¨å±€å˜é‡ã€è·å–èµ„æºæ–‡ä»¶ç­‰åŠŸèƒ½
# 3. å½“æ­¤æ¨¡å—ä½œä¸ºæµç¨‹ç‹¬ç«‹è¿è¡Œæ—¶æ‰§è¡Œmainå‡½æ•°
# 4. å¯è§†åŒ–æµç¨‹ä¸­å¯ä»¥é€šè¿‡"è°ƒç”¨æ¨¡å—"çš„æŒ‡ä»¤ä½¿ç”¨æ­¤æ¨¡å—

import xbot
from xbot import print, sleep
from .import package
from .package import variables as glv

def main(args):
    pass
import unicodedata
import re

def normalize_text(text):
    """
    ç§»é™¤æ–‡æœ¬ä¸­çš„æ‰€æœ‰å˜éŸ³ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦ï¼Œå°†å­—ç¬¦è½¬æ¢ä¸ºåŸºæœ¬å½¢å¼
    ä¾‹å¦‚: lÃ©vÃªque -> leveque, Ğ¹ -> Ğ¸, Ã± -> n, Ã¼ -> u, Ã¦ -> ae, Ã¸ -> o, â„¢ -> TM ç­‰
    """
    # ç‰¹æ®Šå­—ç¬¦æ˜ å°„è¡¨
    special_char_map = {
        # è¿å­—ç¬¦ï¼ˆLigaturesï¼‰
        'Ã¦': 'ae', 'Ã†': 'AE',
        'Å“': 'oe', 'Å’': 'OE',
        'Ä³': 'ij', 'Ä²': 'IJ',
        'ï¬€': 'ff', 'ï¬': 'fi', 'ï¬‚': 'fl', 'ï¬ƒ': 'ffi', 'ï¬„': 'ffl',
        'ï¬…': 'st', 'ï¬†': 'st',
        
        # å¸¦æ–œçº¿æˆ–æ¨ªçº¿çš„å­—æ¯
        'Ã¸': 'o', 'Ã˜': 'O',
        'Ä‘': 'd', 'Ä': 'D',
        'Å‚': 'l', 'Å': 'L',
        'Ä§': 'h', 'Ä¦': 'H',
        'Å§': 't', 'Å¦': 'T',
        'Æ€': 'b', 'Éƒ': 'B',
        'É¨': 'i', 'Æ—': 'I',
        
        # ç‰¹æ®Šç¬¦å·
        'â„¢': 'TM', 'Â®': 'R', 'Â©': 'C',
        'â„ ': 'SM', 'â„—': 'P',
        
        # æ•°å­¦å’ŒæŠ€æœ¯ç¬¦å·
        'Â°': 'deg', 'â„ƒ': 'C', 'â„‰': 'F',
        'â„–': 'No', 'â„®': 'e',
        
        # è´§å¸ç¬¦å·ï¼ˆå¯é€‰ï¼‰
        'â‚¬': 'EUR', 'Â£': 'GBP', 'Â¥': 'JPY', 'â‚¹': 'INR',
        'Â¢': 'c', 'Â¤': 'currency',
        
        # å…¶ä»–ç‰¹æ®Šæ‹‰ä¸å­—æ¯
        'Ã°': 'd', 'Ã': 'D',  # eth
        'Ã¾': 'th', 'Ã': 'TH',  # thorn
        'ÃŸ': 'ss', 'áº': 'SS',  # å¾·è¯­ sharp s
        
        # å¸¦ç‰¹æ®Šè®°å·çš„å­—æ¯
        'Ã¥': 'a', 'Ã…': 'A',
        'Ä…': 'a', 'Ä„': 'A',
        'Ä™': 'e', 'Ä˜': 'E',
        'Ä¯': 'i', 'Ä®': 'I',
        'Å³': 'u', 'Å²': 'U',
        
        # å…¶ä»–å¸¸è§ç‰¹æ®Šå­—ç¬¦
        'É™': 'e',  # schwa
        'É': 'a',  # turned a
        'É”': 'o',  # open o
        'É›': 'e',  # open e
        'Êƒ': 'sh', # esh
        'Ê’': 'zh', # ezh
        'Å‹': 'ng', # eng
        'É²': 'ny', # enye
        'Ê”': "'",  # glottal stop
        
        # æ ‡ç‚¹å’Œå¼•å·
        ''': "'", ''': "'", '"': '"', '"': '"',
        'Â«': '"', 'Â»': '"', 'â€¹': "'", 'â€º': "'",
        'â€”': '-', 'â€“': '-', 'â€¦': '...',
        'â€¢': '*', 'Â·': '.', 'â€š': ',', 'â€': '"',
    }
    
    # é¦–å…ˆåº”ç”¨ç‰¹æ®Šå­—ç¬¦æ˜ å°„
    for char, replacement in special_char_map.items():
        text = text.replace(char, replacement)
    
    # ç„¶åè¿›è¡Œ NFD è§„èŒƒåŒ–å¤„ç†å˜éŸ³ç¬¦å·
    normalized = unicodedata.normalize('NFD', text)
    
    # è¿‡æ»¤æ‰æ‰€æœ‰å˜éŸ³ç¬¦å·å’Œç»„åˆæ ‡è®°
    result = ''.join(c for c in normalized if not unicodedata.combining(c))
    
    # å¯é€‰ï¼šç§»é™¤å…¶ä»–éASCIIå­—ç¬¦ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥å¯ç”¨ï¼‰
    # result = ''.join(c if ord(c) < 128 else ' ' for c in result)
    
    # å¯é€‰ï¼šå¤„ç†å…¶ä»–æœªæ˜ å°„çš„ç‰¹æ®Šå­—ç¬¦
    # é€šè¿‡å­—ç¬¦åç§°æ¥è¯†åˆ«å’Œå¤„ç†
    final_result = []
    for char in result:
        if ord(char) > 127:  # éASCIIå­—ç¬¦
            try:
                char_name = unicodedata.name(char, '').upper()
                # å¤„ç†æŸäº›ç±»å‹çš„å­—ç¬¦
                if 'LETTER' in char_name and 'WITH' in char_name:
                    # å°è¯•è·å–åŸºæœ¬å­—ç¬¦ï¼ˆè¿™ä¼šæ•è·ä¸€äº›é—æ¼çš„å˜éŸ³å­—ç¬¦ï¼‰
                    base_char = char_name.split(' WITH')[0].split()[-1].lower()
                    if len(base_char) == 1:
                        final_result.append(base_char)
                        continue
                elif 'LIGATURE' in char_name:
                    # å¤„ç†å…¶ä»–è¿å­—
                    parts = char_name.replace('LATIN ', '').replace('LIGATURE ', '').lower()
                    final_result.append(parts)
                    continue
            except:
                pass
            final_result.append(char)
        else:
            final_result.append(char)
    
    return ''.join(final_result)


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    test_texts = [
        "lÃ©vÃªqueâ„¢ with Ã¦ther and Ã¸re",
        "CafÃ©Â® with Å’uvre and ÅÃ³dÅº",
        "Temperature: 25â„ƒ or 77â„‰",
        "CopyrightÂ© 2024â„¢ - All rights reservedÂ®",
        "naÃ¯ve rÃ©sumÃ© piÃ±ata Ã¼ber",
        "Ã…se's Ã˜rsted Ã¦gg",
        "â„–1 bestâ„¢ cafÃ©",
        "ğ•³ğ–Šğ–‘ğ–‘ğ–” ğ–‚ğ–”ğ–—ğ–‘ğ–‰",  # ç‰¹æ®Šå­—ä½“
        "ĞœĞ¾ÑĞºĞ²Ğ° ZÃ¼rich KÃ¸benhavn",
    ]
    
    print("åŸå§‹æ–‡æœ¬ -> è§„èŒƒåŒ–æ–‡æœ¬")
    print("-" * 50)
    for text in test_texts:
        normalized = normalize_text(text)
        print(f"{text} -> {normalized}")
